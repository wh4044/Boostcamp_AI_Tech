{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893927cf",
   "metadata": {},
   "source": [
    "# torch.nn.Module\n",
    "\n",
    "- 딥러닝을 구성하는 Layer의 base class이다.\n",
    "- Input, Output, Forward, Backward 정의.\n",
    "- 학습의 대상이 되는 parameter(tensor)정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d773d21",
   "metadata": {},
   "source": [
    "# nn.Parameter\n",
    "- Tensor 객체의 상속 객체이다.\n",
    "- nn.Moduel 내에 attribute가 될 때는 required_grad = True로 지정되어 학습 대상이 되는 Tensor이다.\n",
    "- 우리가 직접 지정할 일을 거의 없다 : 대부분의 layer에는 weights 값들이 랜덤으로 지정되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d10e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "        \n",
    "    def forward(self, x : Tensor):\n",
    "        return x @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51cadc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7332, 0.7757, 0.2484, 0.3988, 0.8468, 0.2754, 0.7514],\n",
       "        [0.8365, 0.3978, 0.8459, 0.7296, 0.2751, 0.7394, 0.0685],\n",
       "        [0.9326, 0.5518, 0.6156, 0.4330, 0.8955, 0.1371, 0.3377],\n",
       "        [0.4334, 0.5491, 0.2649, 0.6783, 0.7168, 0.8606, 0.1537],\n",
       "        [0.4511, 0.9935, 0.4142, 0.4726, 0.6099, 0.4564, 0.9703]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,7)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c42741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1679,  1.1500, -0.2414,  2.2877,  1.3634,  1.2104, -0.5801, -1.0761,\n",
       "         -0.9805, -1.7032, -0.7413, -0.2616],\n",
       "        [-0.9858, -0.7790, -0.8876,  2.3111,  0.1967,  1.0963,  1.5948, -1.3491,\n",
       "          1.1356,  0.8453, -1.9169,  0.0304],\n",
       "        [-0.6134,  0.5531, -0.2136,  3.4132,  1.4128,  0.8275,  0.4250, -0.4719,\n",
       "          0.2437, -0.3498, -1.4633, -0.6636],\n",
       "        [-0.5422, -0.5667, -1.0759,  2.3869, -0.0430,  1.6814,  0.8335, -1.1540,\n",
       "         -0.5942,  0.5446, -1.2121, -0.3886],\n",
       "        [ 0.3170,  0.7321, -0.4113,  2.0468,  1.0104,  0.8533, -1.4176, -2.5376,\n",
       "         -1.2290, -1.7428, -1.0542,  0.0621]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyLinear(7, 12)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c382e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88645dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.7454,  1.1068, -0.0402, -1.0817,  1.0117,  0.2232,  1.7691,  1.5760,\n",
       "           0.7920, -1.1751,  0.1174,  0.1058],\n",
       "         [ 0.7390,  0.4550, -0.1149,  0.1784,  0.1279, -0.9832, -1.4799, -1.5656,\n",
       "           0.2189,  0.0582, -0.2667, -0.8070],\n",
       "         [ 0.3739, -1.3945, -0.2377,  2.0178,  0.3494, -1.6398,  0.1104, -1.0367,\n",
       "           0.5757,  1.3210, -2.1113, -0.3058],\n",
       "         [-0.2138, -0.1919,  0.0431, -0.5453, -1.2300,  1.2174,  0.2663, -1.7177,\n",
       "           2.1782,  0.6055,  0.5820,  1.0517],\n",
       "         [ 0.3863, -0.3415, -0.3846,  2.1309,  0.6236, -0.2094,  0.3669,  0.9587,\n",
       "          -1.4542,  0.4732, -0.7349, -1.0719],\n",
       "         [ 0.0999, -1.2597, -1.3965, -0.7517, -0.3921,  0.1092,  1.5462,  0.2318,\n",
       "          -1.8276,  0.2938, -0.8908, -0.0254],\n",
       "         [ 0.6440,  0.8575,  0.1899, -1.0899,  0.7124,  0.1493, -1.1293, -0.8793,\n",
       "          -1.5656, -2.6893,  0.3315,  1.1568]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.0409,  0.4002,  0.4867,  1.8803, -0.0290,  1.7663, -0.7507, -0.2893,\n",
       "          0.1684,  0.0829,  0.2904, -0.0113], requires_grad=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f082e5",
   "metadata": {},
   "source": [
    "# Backward\n",
    "- Layer에 있는 Parameter들의 미분을 수행한다.\n",
    "- Forward의 결과값(model의 output => 예측치)과 실제값 간의 차이(loss)에 대해 미분을 수행한다.\n",
    "- 해당 값으로 Parameter를 업데이트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a7f69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1for i in x_train]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd45129a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]], dtype=float32),\n",
       " array([[ 1.],\n",
       "        [ 3.],\n",
       "        [ 5.],\n",
       "        [ 7.],\n",
       "        [ 9.],\n",
       "        [11.],\n",
       "        [13.],\n",
       "        [15.],\n",
       "        [17.],\n",
       "        [19.],\n",
       "        [21.]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef1f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "870b4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = 1\n",
    "outputDim = 1\n",
    "learningRate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "model = LinearRegression(inputDim, outputDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e67e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cef7ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(118.5685, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4350, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3888, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3475, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2776, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2218, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1982, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1771, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = Variable(torch.from_numpy(x_train))\n",
    "labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24c78394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26, 1.0\n",
      "2.36, 3.0\n",
      "4.47, 5.0\n",
      "6.58, 7.0\n",
      "8.68, 9.0\n",
      "10.79, 11.0\n",
      "12.90, 13.0\n",
      "15.01, 15.0\n",
      "17.11, 17.0\n",
      "19.22, 19.0\n",
      "21.33, 21.0\n"
     ]
    }
   ],
   "source": [
    "# 실제 값과 비교해보기\n",
    "y = model(Variable(torch.from_numpy(x_train)))\n",
    "\n",
    "for i, j in zip(y, y_train):\n",
    "    print(f\"{i.item():.2f}, {j.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e94f1b",
   "metadata": {},
   "source": [
    "# Backward from the scratch\n",
    "- 실제 backward는 Module 단계에서 직접 지정가능\n",
    "- Module에서 backward와 optimizer 오버라이딩\n",
    "- 사용자가 직접 미분 수식을 써야하는 부담 -> 쓸 일은 없으나 순서는 이해해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d435bc7d",
   "metadata": {},
   "source": [
    "# *Reference*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74729ac5",
   "metadata": {},
   "source": [
    "1. [PyTorch로 Linear Regression 하기](https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817)\n",
    "\n",
    "2. [PyTorch로 Logistic Regression 하기](https://medium.com/dair-ai/implementing-a-logistic-regression-model-from-scratch-with-pytorch-24ea062cd856)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20164d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
