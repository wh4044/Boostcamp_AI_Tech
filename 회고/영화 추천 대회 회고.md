- Data EDA
    - 주 학습 데이터(train_ratings.csv), 영화 제목(titles.tsv), 영화 개봉년도(years.tsv), 영화 장르(genres.tsv)에 집중했다.
    - 31,360명의 사용자, 6807개의 영화가 있었으며 약 510만여개의 평가 데이터가 있었다.
    - ‘드라마’ 장르에 대한 평가 이력이 가장 많았으며 가장 많이 평가된 영화는 ‘매트릭스’, ‘파이트클럽’, ‘펄프픽션’, ‘쇼생크 탈출’ 등 이름만 들어도 알만한 유명한 영화들이 많이 있었다. 또한 1990~2000년도의 영화들이 주를 이루었다는것을 알게되었다.
    - 위 사실로부터 추천된 영화들의 추세도 ‘드라마’ 장르, 유명했던 영화, 90~00년대의 것으로 나오기를 기대했다.

<br></br>
- 모델 구성 과정
    - DeepFM
        - Negative sampling과 Side-information을 활용한 딥러닝 모델을 구성했다.
        - inference 코드를 직접 구성하고 성능을 확인해봤지만 0.08대의 점수를 기록하였다.
        - 훈련 시간 및 성능 저하로 인해 다른 모델로 진행하였다.
    - Multi-VAE, Multi-DAE
        - Auto-Encoder 기반의 딥러닝 모델로 진행해보았다.
        - 튜닝을 통해 최선의 성능을 내는 각각의 단일 모델은 VAE : 0.1348, DAE : 0.1386의 성능을 냈다.
        - Multi-VAE와 Multi-DAE의 성능을 앙상블하니 0.1465가 나왔다. 앙상블의 효과를 새삼 느끼게 된 계기였다.
    - RecVAE
        - RecVAE의 단일 성능이 0.1493으로 VAE와 DAE를 앙상블한 것보다 성능이 높게 나왔다.
        - RecVAE + Multi-VAE + Multi-DAE 앙상블로 0.1510을 기록했다.
    - EASE
        - EASE의 단일 모델이 0.1599로 놀라운 성능을 내주었다. 지그시가 진행한 H+ vamp 모델과 함께 여러 시행착오 끝에 Multi-VAE, DAE를 제외하여 가중치를 조정한 결과, 최종 선정된 모델의 성능은 0.1622로 나왔다.
        
    - 그 외에 시도했던 많은 모델들
        - 사실 이보다 더 많은 모델을 도전하고 적용해보기 위해 노력했지만 기술적, 시간상의 문제로 인해 아쉽게 채택되지 못한 모델이 많이있다.  이 모델들은 꼭 다음에 접수해주기로 마음 먹었다.
    
<br></br>
- 마무리
    - 대회를 위해 팀원 모두들 밤낮없이 열심히 해줘서 정말 멋있고 고마웠다. 여러 논문을 찾아보면서 모델에 적용해보기 위해 고민하고 시도해보는 것이 굉장히 멋있었고 배우고 싶은 점이었다. EDA로부터 특이점을 찾아내고 여러가지 창의적인 방법으로 시도를 해내는 것이 인상깊었으며 정말 팀원들이 없었더라면 해내지 못할 일들을 해낸 것 같아 굉장히 뿌듯하다.
    
    - 시간만 더 있었다면 아직 적용해보지 못한 여러 모델들을 더 파보고 공부할 수 있을 것 같은데 모두가 그렇듯이 시간관계상 그러지 못했다... 꼭 다음 대회에는 이번 대회 경험을 토대로 더 열심히 공부하고 대비해야겠다!